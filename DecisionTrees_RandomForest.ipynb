{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP : Arbres de décision et fôrets aléatoires\n",
    "\n",
    "\n",
    "## Résumé\n",
    "\n",
    "Un arbre de décision est un modèle de classification hiérarchique : à chaque noeud de l'arbre\n",
    "est associé un test sur une des dimensions $x_i$ de la forme $x_i \\{\\leq,~ >,~ = \\} s$ ($s$ une valeur réelle) qui indique le noeud fils qui doit être sélectionné (par exemple pour un arbre binaire, le fils gauche quand le test est vrai, le fils droit sinon). A chaque feuille de l'arbre est associée une étiquette. Ainsi, la classification d'un exemple consiste en une succession de tests sur les valeurs des dimensions de l'exemple, selon un chemin dans l'arbre de la racine à une des feuilles. La feuille atteinte donne la classe prédite.\n",
    "\n",
    "L'apprentissage de l'arbre s'effectue de manière récursive top-down : à chaque noeud, l'algorithme choisit le split vertical (seuillage\n",
    "d'une variable) qui optimise une mesure d'homogénéité sur la partition obtenue (usuellement l'[entropie de shanon](http://fr.wikipedia.org/wiki/Entropie_de_Shannon#D.C3.A9finition_formelle) ou l'[index de Gini](http://fr.wikipedia.org/wiki/Coefficient_de_Gini) : l'entropie d'une partition est d'autant plus petite qu'une classe prédomine dans chaque sous-\n",
    "ensemble de la partition, elle est nulle lorsque la séparation est parfaite).\n",
    "\n",
    "Bien que l'algorithme pourrait continuer récursivement jusqu'à n'obtenir que des feuilles contenant un ensemble pur d'exemples (d'une seule classe), on utilise souvent des critères d'arrêts (pourquoi ? - nous y reviendrons lors de ce TP). Les plus communs sont les suivants :\n",
    "\n",
    "+ le nombre d'exemples minimum que doit contenir un noeud\n",
    "\n",
    "+ la profondeur maximale de l'arbre\n",
    "\n",
    "+ la différence de gain de la mesure d'homogénéité entre le noeud père et les noeuds fils\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prise en main sklearn, données artificielles\n",
    "scikit-learn est un des modules de machine learning les plus populaires (installation : pip install scikit-learn --user).\n",
    "Il contient les algos que nous avons déjà vu (knn, noyaux, perceptron, regression), et bien d'autres outils et algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # module pour les outils mathématiques\n",
    "import matplotlib.pyplot as plt # module pour les outils graphiques\n",
    "import tools # module fourni en TP1\n",
    "from sklearn import tree, linear_model # module pour les arbres\n",
    "from sklearn import ensemble # module pour les forets\n",
    "from sklearn import cross_validation as cv\n",
    "from IPython.display import Image\n",
    "import pydot\n",
    "\n",
    "#que pour jupyter  !!\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les modeles d'apprentissage sous scikit fonctionnent de la manière suivante :\n",
    "\n",
    "+ création du classifieur (ici  **cls=Classifier()**)\n",
    "\n",
    "+ réglage des paramètres (par exemple la profondeur maximale, le nombre d'exemples par noeud)\n",
    "\n",
    "+ apprentissage du classifieur par l'intermédiaire de la fonction **cls.fit(data,labels)** \n",
    "\n",
    "+ prediction pour de nouveaux exemples : fonction **cls.predict(data)**\n",
    "\n",
    "+ score du classifieur (précision, pourcentage d'exemples bien classés) : fonction **cls.score(data,labels)**\n",
    "\n",
    "Pour un arbre de décision, la classe est **tree.DecisionTreeClassfier()**.\n",
    "Dans le cas des arbres de décisions, nous avons aussi la possibilité d'obtenir l'importance des variables, un score qui est d'autant plus grand que la variable est \"utile\" pour la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Initialisation\n",
    "data,y=tools.gen_arti()\n",
    "mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "mytree.max_depth=8 #profondeur maximale de 5\n",
    "mytree.min_samples_split=1 #nombre minimal d'exemples dans une feuille\n",
    "#Apprentissage\n",
    "mytree.fit(data,y)\n",
    "\n",
    "#prediction\n",
    "pred=mytree.predict(data)\n",
    "print (\"precision : \", (1.*pred!=y).sum()/len(y))\n",
    "\n",
    "#ou directement pour la precision : \n",
    "print (\"precision (score) : \"  + str(mytree.score(data,y)))\n",
    "\n",
    "#Importance des variables :\n",
    "plt.subplot(1,2,2)\n",
    "plt.bar([1,2],mytree.feature_importances_)\n",
    "plt.title(\"Importance Variable\")\n",
    "plt.xticks([1,2],[\"x1\",\"x2\"])\n",
    "\n",
    "\n",
    "    \n",
    "###### Si graphviz n'est pas installe, la fonction suivante permet d'afficher un arbre\n",
    "def affiche_arbre(tree):\n",
    "    long = 10\n",
    "    sep1=\"|\"+\"-\"*(long-1)\n",
    "    sepl=\"|\"+\" \"*(long-1)\n",
    "    sepr=\" \"*long\n",
    "    def aux(node,sep):\n",
    "        if tree.tree_.children_left[node]<0:\n",
    "            ls =\"(%s)\" % (\", \".join( \"%s: %d\" %(tree.classes_[i],int(x)) for i,x\n",
    " in enumerate(tree.tree_.value[node].flat)))\n",
    "            return sep+sep1+\"%s\\n\" % (ls,)\n",
    "        return (sep+sep1+\"X%d<=%0.2f\\n\"+\"%s\"+sep+sep1+\"X%d>%0.2f\\n\"+\"%s\" )% \\\n",
    "                    (tree.tree_.feature[node],tree.tree_.threshold[node],aux(tree.tree_.children_left[node],sep+sepl),\n",
    "                    tree.tree_.feature[node],tree.tree_.threshold[node],aux(tree.tree_.children_right[node],sep+sepr))\n",
    "    return aux(0,\"\")\n",
    "print(affiche_arbre(mytree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TREE(data_type, nbex, epsilon, depth, nb_min):\n",
    "    eps = epsilon\n",
    "    datax,y = tools.gen_arti(data_type,nbex,epsilon = eps)\n",
    "    # Affichage des données\n",
    "    tools.plot_data(datax,y)\n",
    "    plt.show()\n",
    "    mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "    mytree.max_depth=depth #profondeur maximale de 5\n",
    "    mytree.min_samples_split=nb_min #nombre minimal d'exemples dans une feuille\n",
    "    #Apprentissage\n",
    "    mytree.fit(data,y)\n",
    "\n",
    "    #prediction\n",
    "    pred=mytree.predict(data)\n",
    "    print (\"precision : \", (1.*pred!=y).sum()/len(y))\n",
    "\n",
    "    #ou directement pour la precision : \n",
    "    print (\"precision (score) : \"  + str(mytree.score(data,y)))\n",
    "\n",
    "    #Importance des variables :\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.bar([1,2],mytree.feature_importances_)\n",
    "    plt.title(\"Importance Variable\")\n",
    "    plt.xticks([1,2],[\"x1\",\"x2\"])\n",
    "\n",
    "    print(affiche_arbre(mytree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TREE(data_type=1, nbex=1000, epsilon=0.1, depth=8, nb_min=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TREE(data_type=2, nbex=1000, epsilon=0.1, depth=8, nb_min=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données générées artificiellement\n",
    "\n",
    "\n",
    "Nous constatons que plus l'arbre est profond, plus la précision est bonne. Cependant il faut éviter le sur-apprentissage. Une validation croisé pour trouver la profondeur et le nombre minimum d'exemple par noeud semble nécessaire.\n",
    "\n",
    "L'erreur indiquée n'est pas donc pertinente sans données de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisée : sélection de modèle\n",
    "\n",
    "Il est rare de disposer en pratique d'un ensemble de test (on préfère inclure le plus grand\n",
    "nombre de données dans l'ensemble d'apprentissage). Pour sélectionner un modèle tout en considérant le plus grand nombre d'exemples possible pour l'apprentissage, on utilise généralement\n",
    "une procédure dite de sélection par validation croisée. Pour chaque paramètrisation du problème,\n",
    "une estimation de l'erreur empirique du classifieur appris est faîte selon la procédure suivante :\n",
    "\n",
    "+ l'ensemble d'apprentissage $E_{app}$ est partitioné en $n$ ensembles d'apprentissage $\\{E_i\\}$\n",
    "\n",
    "+ Pour $i=1..n$\n",
    "\n",
    "  + l'arbre est appris sur $E_{app}$\\ $E_i$\n",
    "\n",
    "  + l'erreur en test $err(E_i)$ est évaluée sur $E_i$ (qui n'a pas servi à l'apprentissage à cette itération)\n",
    "\n",
    "+ l'erreur moyenne $err=\\frac{1}{n}\\sum_{i=1}^n err(E_i)$ est calculée, le modèle sélectionné est celui qui minimise cette erreur\n",
    "\n",
    "\n",
    "Ci-dessous quelques fonctions utiles pour la sélection de modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datax,y = tools.gen_arti(data_type=2,nbex=1000,epsilon=1)\n",
    "#permet de partager un ensemble en deux ensembles d'apprentissage et de test \n",
    "mytree=tree.DecisionTreeClassifier()\n",
    "mytree.max_depth=8\n",
    "mytree.min_samples_split=1\n",
    "# Split 30% test\n",
    "data_train,data_test,y_train,y_test=cv.train_test_split(data,y,test_size=0.3)\n",
    "mytree.fit(data_train,y_train)\n",
    "print (\"precision en test (split 30 %) : \", mytree.score(data_test,y_test))\n",
    "\n",
    "#permet d'executer une n-validation croisée et d'obtenir le score pour chaque tentative\n",
    "print (\"precision en test (10-fold validation) : \",cv.cross_val_score(mytree,data,y,cv=10).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Score en fonction de la profondeur\n",
    "l = range(1,30)\n",
    "score_test = []\n",
    "score_train = []\n",
    "score_kfold = []\n",
    "data,y = tools.gen_arti(data_type=0,nbex=1000,epsilon=1)\n",
    "data_train,data_test,y_train,y_test = cv.train_test_split(data,y,test_size=0.3)\n",
    "mytree.fit(data_train,y_train)\n",
    "for i in l:\n",
    "    mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "    mytree.max_depth=i\n",
    "    mytree.min_samples_split=5 \n",
    "    mytree.fit(data_train,y_train)\n",
    "    score_train.append(mytree.score(data_train,y_train))\n",
    "    score_test.append(mytree.score(data_test,y_test))\n",
    "    score_kfold.append(cv.cross_val_score(mytree,data,y,cv=10).mean())\n",
    "\n",
    "plt.plot(l, score_test) # en vert   \n",
    "plt.plot(l,score_train)\n",
    "plt.plot(l, score_kfold)\n",
    "\n",
    "plt.title(\"Score en fonction de la profondeur (min_sample = 5, data_type = 0)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Score en fonction de la profondeur\n",
    "l = range(1,30)\n",
    "score_test = []\n",
    "score_train = []\n",
    "score_kfold = []\n",
    "data,y = tools.gen_arti(data_type=0,nbex=1000,epsilon=1)\n",
    "data_train,data_test,y_train,y_test = cv.train_test_split(data,y,test_size=0.3)\n",
    "mytree.fit(data_train,y_train)\n",
    "for i in l:\n",
    "    mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "    mytree.max_depth=i\n",
    "    mytree.min_samples_split= 40 \n",
    "    mytree.fit(data_train,y_train)\n",
    "    score_train.append(mytree.score(data_train,y_train))\n",
    "    score_test.append(mytree.score(data_test,y_test))\n",
    "    score_kfold.append(cv.cross_val_score(mytree,data,y,cv=10).mean())\n",
    "\n",
    "plt.plot(l, score_test)   \n",
    "plt.plot(l,score_train)\n",
    "plt.plot(l, score_kfold)\n",
    "\n",
    "plt.title(\"Score en fonction de la profondeur (min_sample = 40, data_type = 0)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le nombre d'exemples par noeud est trop faible, il y a un fort sur-apprentissage (cf premier graphique). Plus on augmente le nombre d'exemples par noeud, plus le sur-apprentissage diminue (écart entre le score d'apprentissage et le score de test). Lorsqu'il y a peu de sur-apprentissage, les deux courbes atteignent leur valeur asymptotique au bout d'une profondeur de 10.\n",
    "\n",
    "L'erreur par 10-fold est plus lisse que celle par par validation croisée car c'est une moyenne.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l = range(1,50)\n",
    "score_test = []\n",
    "score_train = []\n",
    "score_kfold = []\n",
    "data,y = tools.gen_arti(data_type=0,nbex=1000,epsilon=1)\n",
    "data_train,data_test,y_train,y_test = cv.train_test_split(data,y,test_size=0.3)\n",
    "for i in l:\n",
    "    mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "    mytree.max_depth=20\n",
    "    mytree.min_samples_split=i #nombre minimal d'exemples dans une feuille\n",
    "    mytree.fit(data_train,y_train)\n",
    "    score_train.append(mytree.score(data_train,y_train))\n",
    "    score_test.append(mytree.score(data_test,y_test))\n",
    "    score_kfold.append(cv.cross_val_score(mytree,data,y,cv=10).mean())\n",
    "plt.plot(l,score_train)\n",
    "plt.plot(l, score_test)\n",
    "plt.plot(l, score_kfold)\n",
    "plt.title(\"Score en fonction du nombre min d'exemples par noeud (max_depth = 20, data_type = 0)\")\n",
    "plt.show()\n",
    "\n",
    "l = range(1,50)\n",
    "score_test = []\n",
    "score_train = []\n",
    "score_kfold = []\n",
    "data,y = tools.gen_arti(data_type=0,nbex=1000,epsilon=1)\n",
    "data_train,data_test,y_train,y_test = cv.train_test_split(data,y,test_size=0.3)\n",
    "for i in l:\n",
    "    mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "    mytree.max_depth=5\n",
    "    mytree.min_samples_split=i #nombre minimal d'exemples dans une feuille\n",
    "    mytree.fit(data_train,y_train)\n",
    "    score_train.append(mytree.score(data_train,y_train))\n",
    "    score_test.append(mytree.score(data_test,y_test))\n",
    "    score_kfold.append(cv.cross_val_score(mytree,data,y,cv=10).mean())\n",
    "plt.plot(l,score_train)\n",
    "plt.plot(l, score_test)\n",
    "plt.plot(l, score_kfold)\n",
    "plt.title(\"Score en fonction du nombre min d'exemples par noeud (max_depth = 5, data_type = 0)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que plus on augmente le nombre minimal d'exemple par noeud, plus le score de test diminue et le score d'entraînement augmente. Ainsi le sur-apprentissage diminue logiquement mais un sous apprentissage peut apparaitre, de plus on remarque bien ici l'importance de la profondeur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vec2=np.arange(1,11,1) \n",
    "precision_score=[]\n",
    "\n",
    "data,y = tools.gen_arti(data_type=1,nbex=1500)\n",
    "mytree = tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "for i in vec2:\n",
    "    mytree.max_depth=i #profondeur maximale de 5\n",
    "    mytree.min_samples_split=10 #nombre minimal d'exemples dans une feuille\n",
    "    mytree.fit(data,y)\n",
    "    pred=mytree.predict(data)\n",
    "    precision_score.append(mytree.score(data,y))\n",
    "\n",
    "plt.figure().suptitle('precision en fonction de la profondeur, 4 gaussiennes')\n",
    "plt.plot(vec2,precision_score)\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('profondeur')\n",
    "plt.show()\n",
    "\n",
    "vec2=np.arange(1,21,1) \n",
    "#Graphique de la précision en fonction de la profondeur\n",
    "precision_score=[]\n",
    "\n",
    "data,y = tools.gen_arti(data_type=2,nbex=1500)\n",
    "mytree = tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "for i in vec2:\n",
    "    mytree.max_depth=i #profondeur maximale de 5\n",
    "    mytree.min_samples_split=10 #nombre minimal d'exemples dans une feuille\n",
    "    mytree.fit(data,y)\n",
    "    pred=mytree.predict(data)\n",
    "    precision_score.append(mytree.score(data,y))\n",
    "\n",
    "plt.figure().suptitle('precision en fonction de la profondeur, echequier')\n",
    "plt.plot(vec2,precision_score)\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('profondeur')\n",
    "plt.show()\n",
    "\n",
    "vec2=np.arange(1,21,1) \n",
    "#Graphique de la précision en fonction de la profondeur\n",
    "precision_score=[]\n",
    "\n",
    "data,y = tools.gen_arti(data_type=0,nbex=1500,epsilon=1)\n",
    "mytree = tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "for i in vec2:\n",
    "    mytree.max_depth=i #profondeur maximale de 5\n",
    "    mytree.min_samples_split=10 #nombre minimal d'exemples dans une feuille\n",
    "    mytree.fit(data,y)\n",
    "    pred=mytree.predict(data)\n",
    "    precision_score.append(mytree.score(data,y))\n",
    "\n",
    "plt.figure().suptitle('precision en fonction de la profondeur, 2 gaussiennes bruitees')\n",
    "plt.plot(vec2,precision_score)\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('profondeur')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La précision augmente toujours avec la profondeur de l'arbre. On constate par contre que cette evolution n'est pas identique selon le jeu de données:\n",
    "Pour les 4 gaussiennes, une valeur seuil de la profondeur pour avoir un score de 1 apparait.\n",
    "Pour l'échiquier, l'arbre a besoin d'une profondeur plus importante pour séparer et la croissance de la precision selon la profondeur est quasi linéaire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*<font style=\"BACKGROUND-COLOR: lightgray\" color='red'>Manipuler sur les différents types de génération artificielle ces fonctions afin de trouver les meilleurs paramètres selon le problème. Tracer l'erreur d'apprentissage et l'erreur de test en fonction des paramètres étudiés. Que se passe-t-il pour des profondeurs trop élevées des arbres ?</font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification données USPS\n",
    "\n",
    "Tester sur les données USPS (en sélectionnant quelques sous-classes). Observer l'importance des variables. Afficher la matrice 2D de la variable importance de chaque pixel de l'image (avec **plt.imshow(matrix)**). Les résultats semble-t-ils cohérents ? \n",
    "Utiliser l'algorithme du perceptron fourni par sklearn (**linear_model.Perceptron**) ou le votre et comparer les résultats obtenus pour les poids.\n",
    "\n",
    "Sur quelques exemples, comparer les performances des arbres et du Perceptron en utilisant la validation croisée pour calibrer au mieux vos modèles. \n",
    "\n",
    "Expérimenter également les fôrets aléatoires : c'est une méthode de baging très utilisée, qui consiste à considérer un ensemble d'arbres appris chacun sur un échantillonage aléatoire de la base d'exemples; la classification se fait par vote majoritaire (**enemble.RandomForestClassifier()**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def  load_usps(filename):\n",
    "    with open(filename ,\"r\") as f:\n",
    "        f.readline()\n",
    "        data = [[float(x) for x in l.split()] for l in f if len(l.split())>2]\n",
    "    tmp = np.array(data)\n",
    "    return tmp[:,1:],tmp[:,0].astype(int)\n",
    "datax,y = load_usps(\"usps.txt\")\n",
    "plt.imshow(datax[100].reshape((16,16)),interpolation=\"nearest\")\n",
    "plt.colorbar()\n",
    "print(y[0])\n",
    "data_train,data_test,y_train,y_test=cv.train_test_split(datax,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#traçons la précision (score) en fonction de la profondeur \n",
    "l = range(1,30)\n",
    "score_test = []\n",
    "score_train = []\n",
    "#score_kfold = []\n",
    "\n",
    "for i in l:\n",
    "    mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "    mytree.max_depth=i\n",
    "    mytree.min_samples_split=20 #nombre minimal d'exemples dans une feuille 20 !!\n",
    "    mytree.fit(data_train,y_train)\n",
    "    score_train.append(mytree.score(data_train,y_train))\n",
    "    score_test.append(mytree.score(data_test,y_test))\n",
    "    #score_kfold.append(cv.cross_val_score(mytree,datax,y,cv=10).mean())\n",
    "    \n",
    "plt.plot(l,score_train)\n",
    "plt.plot(l, score_test)\n",
    "#plt.plot(l, score_kfold)\n",
    "plt.title(\"Score en fonction de la profondeur (min_sample = 20, USPS)\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "l = range(1,50)\n",
    "score_test = []\n",
    "score_train = []\n",
    "#score_kfold = []\n",
    "for i in l:\n",
    "    mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "    mytree.max_depth=12\n",
    "    mytree.min_samples_split=i #nombre minimal d'exemples dans une feuille\n",
    "    mytree.fit(data_train,y_train)\n",
    "    score_train.append(mytree.score(data_train,y_train))\n",
    "    score_test.append(mytree.score(data_test,y_test))\n",
    "    #score_kfold.append(cv.cross_val_score(mytree,data,y,cv=10).mean())\n",
    "    \n",
    "plt.plot(l,score_train)\n",
    "plt.plot(l, score_test)\n",
    "#plt.plot(l, score_kfold)\n",
    "plt.title(\"Score en fonction du nombre d'exemples par noeud (max_depth = 12, USPS)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calibrer le modèle, nous obtenons pour limiter le sur-apprentissage et obtenir le meilleur score :\n",
    "- Profondeur : 12\n",
    "- Nombre d'exemples par noeud : 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.Perceptron()\n",
    "model.fit(data_train, y_train)\n",
    "print ('-- Perceptron --')\n",
    "print ('score train : ', model.score(data_train, y_train))\n",
    "print ('score test : ', model.score(data_test, y_test))\n",
    "\n",
    "mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "mytree.max_depth=12\n",
    "mytree.min_samples_split=20 \n",
    "mytree.fit(data_train,y_train)\n",
    "print ('-- Arbre --')\n",
    "print (\"score train : \", mytree.score(data_train,y_train))\n",
    "print ('score test : ', mytree.score(data_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : Le score obtenu par le perceptron linéaire est meilleur que celui pour les abres cela est du au sur-apprentissage qui est plus faible pour le perceptron que pour les arbres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Une classe contre toutes\n",
    "datax,y = load_usps(\"usps.txt\")\n",
    "perc = linear_model.Perceptron()\n",
    "mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "mytree.max_depth=12\n",
    "mytree.min_samples_split=20 \n",
    "\n",
    "usps_6 = datax[y==6]\n",
    "usps_not6 = datax[y!=6]\n",
    "data_usps=np.vstack((usps_6,usps_not6))\n",
    "\n",
    "label_6= -1*np.ones((len(usps_6),1))\n",
    "label_not6=np.ones((len(usps_not6),1))\n",
    "label=np.vstack((label_6,label_not6))\n",
    "\n",
    "data_train,data_test,label_train,label_test=cv.train_test_split(data_usps,label,test_size=0.3)\n",
    "\n",
    "mytree.fit(data_train,label_train)\n",
    "perc.fit(data_train,label_train)\n",
    "print ('score test Perceptron : ', perc.score(data_test,label_test))\n",
    "print ('score test Arbres : ', mytree.score(data_test,label_test))\n",
    "plt.imshow(perc.coef_.reshape((16,16)),interpolation=\"nearest\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Random Forest\n",
    "datax,y = load_usps(\"usps.txt\")\n",
    "data_train,data_test,y_train,y_test=cv.train_test_split(datax,y,test_size=0.3)\n",
    "\n",
    "model = linear_model.Perceptron()\n",
    "model.fit(data_train, y_train)\n",
    "print ('-- Perceptron --')\n",
    "print ('score train : ', model.score(data_train, y_train))\n",
    "print ('score test : ', model.score(data_test, y_test))\n",
    "\n",
    "mytree=tree.DecisionTreeClassifier() #creation d'un arbre de decision\n",
    "mytree.max_depth=12\n",
    "mytree.min_samples_split=20 \n",
    "mytree.fit(data_train,y_train)\n",
    "print ('-- Arbre --')\n",
    "print (\"score train : \", mytree.score(data_train,y_train))\n",
    "print ('score test : ', mytree.score(data_test, y_test))\n",
    "\n",
    "rf=ensemble.RandomForestClassifier() #creation random forest\n",
    "rf.fit(data_train,y_train)\n",
    "print ('-- Random Forest --')\n",
    "print (\"score train : \", rf.score(data_train,y_train))\n",
    "print ('score test : ', rf.score(data_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest consiste à considérer un ensemble d'arbres appris chacun sur un échantillonage aléatoire de la base d'exemples. La classification se fait par vote majoritaire. L'algorithme des forêts d'arbres décisionnels effectue un apprentissage sur de multiples arbres de décision entraînés sur des sous-ensembles de données légèrement différents.\n",
    "\n",
    "On obtient donc logiquement un meilleur score que pour un arbre classique et on peut constater que l'on obtient également un meilleure score que pour le perceptron linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification sur la base movielens \n",
    "\n",
    "La base movielens est une base de données issue d'imdb, qui contient des informations sur des films (le genre, l'année de production, des tags) et des notes attribuées par les utilisateurs. Elle est utilisée généralement pour la recommendation de films. Nous allons l'utiliser dans le cadre de la classification, afin de prédire si un film est bon ou mauvais, dans deux contextes :\n",
    "\n",
    "+ en prenant en compte uniquement l'information sur le film et le score moyen du film\n",
    "\n",
    "+ en prenant en compte l'information de l'utilisateur qui score le film\n",
    "\n",
    "Télécharger l'[archive suivante](http://www-connex.lip6.fr/~baskiotisn/ARF15/imdb_extrait.pkl)\n",
    "\n",
    "Le bloc de code suivant est utilisé pour  charger et prétraiter les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "[data,id2titles, fields]=cPickle.load(file(\"imdb_extrait.pkl\"))\n",
    "datax = data[:,:32]\n",
    "datay= np.array([1 if x[33]>6.5 else -1 for x in data]) # seuil de bon film a 6.5\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
